#!/bin/bash --login
#$ -cwd
#$ -l nvidia_v100            # Can instead use 'nvidia_a100' for the A100 GPUs (if permitted!)

run_command() {
    local data=$1
    local position_agg=$2

    # Use command based on dataset
    if [[ $data == "wikipedia" ]]; then
        if [[ $position_agg == "sum" ]]; then
            python train_self_supervised.py --use_memory --n_runs 3 --n_head 4 --n_layer 2 -pat "sum" --alpha 2 --beta 0.1 --scheduler 15 --gamma 0.1
        elif [[ $position_agg == "exp" || $position_agg == "" ]]; then
            python train_self_supervised.py --use_memory --n_runs 3 --n_head 4 --n_layer 2 -pat "exp" --alpha 2 --beta 0.1 --scheduler 15 --gamma 0.1
            # python train_self_supervised.py --use_memory --n_runs 3 --n_head 4 --n_layer 2 -pat "exp" --alpha 2 --beta 0.05 --lr 0.00001 --scheduler 15 --gamma 0.1 -pd 8 --n_epoch 50
        fi
    elif [[ $data == "reddit" ]]; then
        if [[ $position_agg == "sum" ]]; then
            python train_self_supervised.py -d reddit --use_memory --n_runs 2 --n_layer 2 -pat "sum" --lr 0.00005 --alpha 2 --beta 0.1 --scheduler 15
        elif [[ $position_agg == "exp" || $position_agg == "" ]]; then
            python train_self_supervised.py -d reddit --use_memory --n_runs 2 --n_layer 2 -pat "exp" --lr 0.00005 --alpha 2 --beta 0.1 --scheduler 15
        fi
    elif [[ $data == "mooc" ]]; then
        if [[ $position_agg == "sum" ]]; then
            python train_self_supervised.py --data mooc --use_memory --n_runs 3 --n_layer 2 -pat "sum"
        elif [[ $position_agg == "exp" || $position_agg == "" ]]; then
            python train_self_supervised.py --data mooc --use_memory --n_runs 3 --n_layer 2 -pat "exp" -em "complex_position_attn"
        fi
    elif [[ $data == "lastfm" ]]; then
        if [[ $position_agg == "sum" ]]; then
            python train_self_supervised.py --data lastfm --use_memory --n_runs 3 --n_layer 2 -pat "sum" --alpha 1 -pd 12 -ped 36
        elif [[ $position_agg == "exp" || $position_agg == "" ]]; then
            python train_self_supervised.py --data lastfm --use_memory --n_runs 3 --n_layer 2 -pat "exp" -em "complex_position_attn" --alpha 1 -pd 12 -ped 36
        fi
    elif [[ $data == "wikipedia_fm" ]]; then
        if [[ $position_agg == "sum" ]]; then
            python train_self_supervised.py -d wikipedia_fm --use_memory --n_runs 3 --n_head 4 --n_layer 2 -pat "sum"
        elif [[ $position_agg == "exp" || $position_agg == "" ]]; then
            python train_self_supervised.py -d wikipedia_fm --use_memory --n_runs 3 --n_head 4 --n_layer 2 -pat "exp" --alpha 1 --beta 0.1 -em "complex_position_attn" -pd 8 -ped 24
        fi
    elif [[ $data == "reddit_fm" ]]; then
        if [[ $position_agg == "sum" ]]; then
            python train_self_supervised.py -d reddit_fm --use_memory --n_runs 3 --n_head 4 --n_layer 2 --scheduler 15 -pat "sum"
        elif [[ $position_agg == "exp" || $position_agg == "" ]]; then
            python train_self_supervised.py -d reddit_fm --use_memory --n_runs 3 --n_head 4 --n_layer 2 --scheduler 15 -pat "exp" -em "complex_position_attn"
        fi
    fi
}

module load libs/cuda/11.7.0

# Copy a directory of files from scratch to the GPU node's local NVMe storage
cp -r ~/scratch/papers/TPPGN/ $TMPDIR

# Process the data with a GPU app, from within the local NVMe storage area
cd $TMPDIR/TPPGN/
run_command $1 $2

# Copy the results back to the main scratch area
rsync -av $TMPDIR/TPPGN/log/ ~/scratch/papers/TPPGN/log/
rsync -av $TMPDIR/TPPGN/results/ ~/scratch/papers/TPPGN/results/
rsync -av $TMPDIR/TPPGN/saved_checkpoints/ ~/scratch/papers/TPPGN/saved_checkpoints/
rsync -av $TMPDIR/TPPGN/saved_models/ ~/scratch/papers/TPPGN/saved_models/

# The batch system will automatically delete the contents of $TMPDIR at the end of your job.
cd ~/scratch/papers/TPPGN/
git pull
git add ./log/
git commit -m "logs updated"
git push

sleep 3
#$ -m ea
#$ -M jiafeng.xiong@manchester.ac.uk     # Send email when finished.
